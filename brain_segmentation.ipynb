{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sahichitrapu/Documents/GitHub/Brain-MRI-Segmentation/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "from glob import glob\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.color import rgb2gray\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import Model, load_model, save_model\n",
    "from tensorflow.keras.layers import Input, Activation, BatchNormalization, Dropout, Lambda, Conv2D, Conv2DTranspose, MaxPooling2D, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lgg-mri-segmentation/kaggle_3m/TCGA_CS_6667_20011105/TCGA_CS_6667_20011105_8.tif', 'lgg-mri-segmentation/kaggle_3m/TCGA_CS_6667_20011105/TCGA_CS_6667_20011105_9.tif', 'lgg-mri-segmentation/kaggle_3m/TCGA_CS_6667_20011105/TCGA_CS_6667_20011105_2.tif', 'lgg-mri-segmentation/kaggle_3m/TCGA_CS_6667_20011105/TCGA_CS_6667_20011105_3.tif', 'lgg-mri-segmentation/kaggle_3m/TCGA_CS_6667_20011105/TCGA_CS_6667_20011105_20.tif']\n"
     ]
    }
   ],
   "source": [
    "# Set image dimensions\n",
    "im_width = 256\n",
    "im_height = 256\n",
    "\n",
    "# Load FLAIR mask and MRI images from dataset\n",
    "mask_files = glob(\"lgg-mri-segmentation/kaggle_3m/*/*_mask*\")\n",
    "mri_files = []\n",
    "\n",
    "for file in mask_files:\n",
    "    mri_files.append(file.replace('_mask', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot MRI images with FLAIR mask filter\n",
    "def plot_masked_mri(rows, cols, mri_path_list, mask_path_list):\n",
    "    fig = plt.figure(figsize=(12, 12))\n",
    "    for i in range(1, rows * cols + 1):\n",
    "        fig.add_subplot(rows, cols, i)\n",
    "        # Show images of corresponding mask/MRI from file path\n",
    "        mri_path = mri_path_list[i]\n",
    "        mask_path = mask_path_list[i]\n",
    "        mri = cv2.imread(mri_path)\n",
    "        mri = cv2.cvtColor(mri, cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.imread(mask_path)\n",
    "        plt.imshow(mri)\n",
    "        plt.imshow(mask, alpha = 0.4)\n",
    "    plt.show()\n",
    "\n",
    "# 3x3 grid\n",
    "plot_masked_mri(3, 3, mri_files, mask_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "im_data = pd.DataFrame(data = {'mri_files': mri_files, 'mask_files': mask_files})\n",
    "\n",
    "# Split data into train and test\n",
    "im_train, im_test = train_test_split(im_data, test_size = 0.1)\n",
    "\n",
    "# Split test into validation and test\n",
    "im_val, im_test = train_test_split(im_test, test_size = 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator(df, batch_size, aug_dict, mri_color='rgb', mask_color='grayscale', mri_save='image', mask_save='mask', save_to=None, target_size=(256, 256), seed=1):\n",
    "    mri_data_generator = ImageDataGenerator(**aug_dict)\n",
    "    mask_data_generator = ImageDataGenerator(**aug_dict)\n",
    "\n",
    "    mri_gen = mri_data_generator.flow_from_dataframe(\n",
    "        df,\n",
    "        x_col = \"mri_files\",\n",
    "        class_mode = None,\n",
    "        color_mode = mri_color,\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        save_to_dir = save_to,\n",
    "        save_prefix = mri_save,\n",
    "        seed = seed\n",
    "    )\n",
    "\n",
    "    mask_gen = mask_data_generator.flow_from_dataframe(\n",
    "        df,\n",
    "        x_col = \"mask_files\",\n",
    "        class_mode = None,\n",
    "        color_mode = mask_color,\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        save_to_dir = save_to,\n",
    "        save_prefix = mask_save,\n",
    "        seed = seed\n",
    "    )\n",
    "\n",
    "    train_gen = zip(mri_gen, mask_gen)\n",
    "\n",
    "    for (mri, mask) in train_gen:\n",
    "        mri, mask = normalized_diagnosis(mri, mask)\n",
    "        yield (mri, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_diagnosis(mri, mask):\n",
    "    mri /= 255\n",
    "    mask /= 255\n",
    "    mask[mask > 0.5] = 1\n",
    "    mask[mask <= 0.5] = 0\n",
    "    return (mri, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coefficient(actual, pred, smooth_factor):\n",
    "    actual_flatten = K.flatten(actual)\n",
    "    pred_flatten = K.flatten(pred)\n",
    "    \n",
    "    intersect = K.sum(actual_flatten, pred_flatten)\n",
    "    union = K.sum(actual_flatten) + K.sum(pred_flatten)\n",
    "\n",
    "    return (2 * intersect + smooth_factor) / (union + smooth_factor)\n",
    "\n",
    "def dice_loss(actual, pred):\n",
    "    return -dice_coefficient(actual, pred)\n",
    "\n",
    "def intersect_over_union(actual, pred, smooth_factor):\n",
    "    intersect = K.sum(actual * pred)\n",
    "    union = K.sum(actual + pred)\n",
    "    return (intersect + smooth_factor) / (union - intersect + smooth_factor)\n",
    "\n",
    "\n",
    "def jaccard(actual, pred):\n",
    "    actual_flatten = K.flatten(actual)\n",
    "    pred_flatten = K.flatten(pred)\n",
    "    return -intersect_over_union(actual_flatten, pred_flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(inputs, filters):\n",
    "    conv1 = Conv2D(filters, 3, padding='same')(inputs)\n",
    "    act1 = Activation('relu')(conv1)\n",
    "    conv1 = Conv2D(filters, 3, padding='same')(act1)\n",
    "    act1 = Activation('relu')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2), strides=2)(act1)\n",
    "\n",
    "    return pool1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(inputs, skip_features, filters):\n",
    "    conv1 = Conv2DTranspose(filters, (2, 2), strides=2, padding='same')(inputs)\n",
    "    skip_features = tf.image.resize(skip_features, size=(conv1.shape[1], conv1.shape[2]))\n",
    "    up1 = Concatenate()([conv1, skip_features])\n",
    "    conv1 = Conv2D(filters, 3, padding='same')(up1)\n",
    "    act1 = Activation('relu')(conv1)\n",
    "    conv1 = Conv2D(filters, 3, padding='valid')(act1)\n",
    "    act1 = Activation('relu')(conv1)\n",
    "\n",
    "    return act1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_model(input_size = (256, 256, 3)):\n",
    "    inp = Input(input_size)\n",
    "\n",
    "    cont1 = encoder(inp, 64)\n",
    "    cont2 = encoder(cont1, 128)\n",
    "    cont3 = encoder(cont2, 256)\n",
    "    cont4 = encoder(cont3, 512)\n",
    "\n",
    "    conv_bn = Conv2D(1024, 3, padding='same')(cont4)\n",
    "    act_bn = Activation('relu')(conv_bn)\n",
    "    conv_bn = Conv2D(1024, 3, padding='same')(act_bn)\n",
    "    act_bn = Activation('relu')(conv_bn)\n",
    "\n",
    "    exp1 = decoder(act_bn, cont4, 512)\n",
    "    exp2 = decoder(exp1, cont3, 256)\n",
    "    exp3 =  decoder(exp2, cont2, 128)\n",
    "    exp4 = decoder(exp3, cont3, 64)\n",
    "\n",
    "    out = Conv2D(1, 1, padding='same', activation='sigmoid')(exp4)\n",
    "    model = Model(inputs = inp, outputs=out, name='U-Net')\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator_param = dict(\n",
    "    rotation_range=0.2,\n",
    "    width_shift_range=0.05,\n",
    "    height_shift_range=0.05,\n",
    "    shear_range=0.05,\n",
    "    zoom_range=0.05,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "train_gen = train_generator(im_train, 32, train_generator_param, target_size=(im_height, im_width))\n",
    "test_gen = train_generator(im_test, 32, dict(), target_size=(im_height, im_width))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-brain-segmentation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
